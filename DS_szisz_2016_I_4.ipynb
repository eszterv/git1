{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science @ SzISz Part III.\n",
    "## Dimensionality Reduction\n",
    "\n",
    "### Table of contents\n",
    "- <a href=\"#What-is-Dimensionality-Reduction?\">Theory</a>\n",
    "- <a href=\"#Feature-Selection\">Feature Selection</a>\n",
    "- <a href=\"#Matrix-Decomposition\">Matrix Decomposition</a>\n",
    "- <a href=\"#Other-Techniques\">Other Techniques</a>\n",
    "\n",
    "## What is Dimensionality Reduction?\n",
    "Dimensionality reduction _\"is the process of reducing the number of random variables under consideration, and can be divided into feature selection and feature extraction.\"_\n",
    "\n",
    "_\"__Feature selection__ approaches try to find a subset of the original variables. ... In some cases, data analysis such as regression or classification can be done in the reduced space more accurately than in the original space.\"_\n",
    "\n",
    "_\"__Feature extraction__ transforms the data in the high-dimensional space to a space of fewer dimensions. The data transformation may be linear, as in principal component analysis (PCA), but many nonlinear dimensionality reduction techniques also exist.\"_ from:<a href=\"https://en.wikipedia.org/wiki/Dimensionality_reduction\">Wikipedia</a>\n",
    "\n",
    "\n",
    "## Why is it important?\n",
    "With hundreds of features in the datasets, there will always be some which does not contribute to the overall precision of the predictive model. These features could be redundant, overlapping or linear combination of each other or simply irrelevant to the prediction. To improve training and transformation/prediction time, it is crucial to reduce the number of features to a moderate amount.\n",
    "\n",
    "The <a href=\"https://en.wikipedia.org/wiki/Curse_of_dimensionality\">curse of dimensionality</a> also requires one to deal with the dimensionality concerns.\n",
    "\n",
    "\n",
    "## Tools\n",
    "- <a href=\"http://scikit-learn.org/stable/modules/feature_selection.html\">Feature Selection</a>\n",
    "- <a href=\"http://scikit-learn.org/stable/modules/decomposition.html#decompositions\">Matrix decomposition</a>\n",
    "- <a href=\"http://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing\">Hashing</a>\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#minél több dimenziónk van, annál több adat kell egy item leírásához\n",
    "#egyre több futásidő, egyre többmemória\n",
    "#vagy manuálisan vagy vmelyien módszerrel kiválasztjuka számunkra leginkább információt adó feature-et\n",
    "#variance treshold: bizonyos tresholdnál kisebb varianciájú változókat elhagyunk\n",
    "from sklearn.svm import SVR, LinearSVC\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__VarianceThreshold__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5154c3a7318c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mthres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVarianceThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_t\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "#nem veszi figyelembe, ha a változók különböző skálán vannak\n",
    "#érdemes először standardizálni\n",
    "thres=VarianceThreshold(0.4)\n",
    "X_t=thres.fit_transform(X)\n",
    "X_t.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RFE__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rekursive feature elimination\n",
    "#osztályozó: először benne van az összes feature, majd kivesz belőle és emgnézi romlik-e vele az eredmény\n",
    "#külső becslő kell neki\n",
    "#support vector machines: próbálunkolyan egyenest húzni, ami az osztályokat elválasztja egymástól\n",
    "#cél a margómaximalizálása\n",
    "#kernel függvények: adathalmaz transzformációja, ahol már lineárisan szeparálható a feladat\n",
    "#nem kell minden tagok áttranszformálni az új térbe, elég bővíteni a távolságdefiníciót\n",
    "svr=SVR(kernel=\"linear\", C=0.01)\n",
    "rfe=RFE(svr, n_features_to_select=2)\n",
    "X_t= rfe.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.ranking_ #a paraméterek értékei, meddig maradtak bent,mikor estek ki\n",
    "rfe.support_#mit hagyjunk ki, mit hagyjunk bent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select from model__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150L, 2L)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=LinearSVC(C=0.01).fit(X, y)\n",
    "sel=SelectFromModel(svc, prefit=True) #it is fotosság szerint paramétereket számít, threshold: benthagyni vs. kivenni\n",
    "#egyébként pedig azt hagyja bent, ami jobb az átlagnál\n",
    "X_t=sel.transform(X)\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#már eleve a tfidf-el transzformált anyagot töltjük le\n",
    "data2 = fetch_20newsgroups_vectorized(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "X2, y2 = data2.data, data2.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__PCA__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCA: \n",
    "pca=PCA('mle')\n",
    "X2_t=pca.fit_transform(X2.todense())\n",
    "X2_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SVD__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532L, 300L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd=TruncatedSVD(n_components=300)\n",
    "X2_t=svd.fit_transform(X2)\n",
    "X2_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "baseline=mean_squared_error(y2, np.ones(y2.shape)*y2.mean())\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X2_t, y2)\n",
    "mean_squared_error(y2, knn.predict(X2_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#minden szónak vezsi a hash-ét\n",
    "#\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "vect=HashingVectorizer(n_features=1024) #1024 értékre fog leképződni az eredetileg 30 akárhányezer szó\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashingVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, n_features=1048576, ngram_range=(1, 1),\n",
       "         non_negative=False, norm=u'l2', preprocessor=None,\n",
       "         stop_words=None, strip_accents=None,\n",
       "         token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "data3= fetch_20newsgroups()\n",
    "X3, y3 = data3.data, data3.target\n",
    "vect.fit(X3, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3[0]\n",
    "vect.transform([X3[0]])\n",
    "vect=HashingVectorizer(n_features=256)\n",
    "#bemenetként dokumentumok listáját várja\n",
    "X3_t=vect.transform(X3).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf=TfidfTransformer()\n",
    "X3_tt=tfidf.fit_transform(X3_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X3_tt, y3)\n",
    "knn.predict(X3_tt)\n",
    "sns.heatmap(confusion_matrix(y3,(knn.predict(X3_tt))))\n",
    "#sorok: valós, oszlopok:prediktált, ha a főátlóban sötétebb, akkor jó a besorolás\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adott modellpontossága:\n",
    "knn.score(X3_tt, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rendezzük az egészet egy pipeline-ba\n",
    "#kimásolni!!!!\n",
    "pipe=Pipiline([('hash', HashingVectorizer, n_features=256), ('tfidf')])\n",
    "\n",
    "pipe.score(X3, y3)\n",
    "sns.heatmap(confusion_matrix(y3, pipe.predict(X3)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
